{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------Create Data\n",
    "\n",
    "pd.DataFrame(np.random.rand(20,5))\t5 columns and 20 rows of random floats\n",
    "pd.Series(my_list)\tCreate a series from an iterable my_list\n",
    "df.index = pd.date_range('1900/1/30', periods=df.shape[0])\n",
    "\n",
    "# ------------------------------------------------------- Selection\n",
    "\n",
    "df[col]                 #\tReturns column with label col as Series\n",
    "df[[col1, col2]]        #\tReturns columns as a new DataFrame\n",
    "s.iloc[0]               #\tSelection by position\n",
    "s.loc['index_one']      #\tSelection by index\n",
    "df.iloc[0,:]            #\tFirst row\n",
    "df.iloc[0,0]            #\tFirst element of first column\n",
    "\n",
    "\n",
    "#-------------------------------------------------------- Viewing/Inspecting Data\n",
    "\n",
    "df.head(n)                 #\tFirst n rows of the DataFrame\n",
    "df.tail(n)                 #\tLast n rows of the DataFrame\n",
    "df.shape                   #\tNumber of rows and columns\n",
    "df.info()                  #\tIndex, Datatype and Memory information\n",
    "df.describe()              #\tSummary statistics for numerical columns\n",
    "s.value_counts(dropna=False)    #\tView unique values and counts\n",
    "df.apply(pd.Series.value_counts)#\tUnique values and counts for all columns\n",
    "\n",
    "# ------------------------------------------------------ Data Cleaning\n",
    "\n",
    "df.columns = ['a','b','c']       #\tRename columns\n",
    "pd.isnull()                      #\tChecks for null Values, Returns Boolean Arrray\n",
    "pd.notnull()                     #\tOpposite of pd.isnull()\n",
    "df.dropna()                      #\tDrop all rows that contain null values\n",
    "df.dropna(axis=1)                #\tDrop all columns that contain null values\n",
    "df.dropna(axis=1,thresh=n)       #\tDrop all rows have have less than n non null values\n",
    "df.fillna(x)                     #\tReplace all null values with x\n",
    "s.fillna(s.mean())               #\tReplace all null values with the mean\n",
    "s.astype(float)                  #\tConvert the datatype of the series to float\n",
    "s.replace(1,'one')               #\tReplace all values equal to 1 with 'one'\n",
    "s.replace([2,3],['two', 'three'])            #\tReplace all 2 with 'two' and 3 with 'three'\n",
    "df.rename(columns=lambda x: x + 1)           #\tMass renaming of columns\n",
    "df.rename(columns={'old_name': 'new_ name'}) #\tSelective renaming\n",
    "df.set_index('column_one')                   #\tChange the index\n",
    "df.rename(index=lambda x: x + 1)             #\tMass renaming of index\n",
    "\n",
    "# ---------------------------------------------------- Filter, Sort, Groupby\n",
    "\n",
    "df[df[col] > 0.6]                                        #\tRows where the column col is greater than 0.6\n",
    "df[(df[col] > 0.6) & (df[col] < 0.8)]                    #\tRows where 0.8 > col > 0.6\n",
    "df.sort_values(col1)                                     #\tSort values by col1 in ascending order\n",
    "df.sort_values(col2,ascending=False)                     #\tSort values by col2 in descending order.5\n",
    "df.sort_values([col1,col2],ascending=[True,False])       #\tSort values by col1 in ascending order then col2 in descending order\n",
    "df.groupby(col)                                          #\tReturns a groupby object for values from one column\n",
    "df.groupby([col1,col2])                                  #\tReturns groupby object for values from multiple columns\n",
    "df.groupby(col1)[col2]                                   #\tReturns the mean of the values in col2, grouped by the values in col1\n",
    "df.pivot_table(index=col1,values=[col2,col3],aggfunc=mean)#\tCreate a pivot table that groups by col1 and calculates the mean of col2 and col3\n",
    "df.groupby(col1).agg(np.mean)                            #\tFind the average across all columns for every unique col1 group\n",
    "df.apply(np.mean)                                        #\tApply the function np.mean() across each column\n",
    "nf.apply(np.max,axis=1)                                  #\tApply the function np.max() across each row\n",
    "\n",
    "# ------------------------------------------------------ Join, Combine\n",
    "\n",
    "df1.append(df2)                          #\tAdd the rows in df1 to the end of df2 (columns should be identical)\n",
    "pd.concat([df1, df2],axis=1)             #\tAdd the columns in df1 to the end of df2 (rows should be identical)\n",
    "df1.join(df2,on=col1, how='inner')       #\tSQL-style join the columns in df1 with the columns on df2 where the rows for col have identical values. The 'how' can be 'left', 'right', 'outer' or 'inner'\n",
    "\n",
    "#------------------------------------------------------- Statistics\n",
    "\n",
    "df.describe()            #\tSummary statistics for numerical columns\n",
    "df.mean()                #\tReturns the mean of all columns\n",
    "df.corr()                #\tReturns the correlation between columns in a DataFrame\n",
    "df.count()               #\tReturns the number of non-null values in each DataFrame column\n",
    "df.max()                 #\tReturns the highest value in each column\n",
    "df.min()                 #\tReturns the lowest value in each column\n",
    "df.median()              #\tReturns the median of each column\n",
    "df.std()                 #\tReturns the standard deviation of each column\n",
    "\n",
    "#------------------------------------------------------- Importing Data\n",
    "\n",
    "pd.read_csv(filename)                   #\tFrom a CSV file\n",
    "pd.read_table(filename)                 #\tFrom a delimited text file (like TSV)\n",
    "pd.read_excel(filename)                 #\tFrom an Excel file\n",
    "pd.read_sql(query, connection_object)   #\tRead from a SQL table/database\n",
    "pd.read_json(json_string)               #\tRead from a JSON formatted string, URL or file.\n",
    "pd.read_html(url)                       #\tParses an html URL, string or file and extracts tables to a list of dataframes\n",
    "pd.read_clipboard()                     #\tTakes the contents of your clipboard and passes it to read_table()\n",
    "pd.DataFrame(dict)                      #\tFrom a dict, keys for columns names, values for data as lists\n",
    "\n",
    "\n",
    "#------------------------------------------------------- Exporting Data\n",
    "\n",
    "df.to_csv(filename)                          #\tWrite to a CSV file\n",
    "df.to_excel(filename)                        #\tWrite to an Excel file\n",
    "df.to_sql(table_name, connection_object)     #\tWrite to a SQL table\n",
    "df.to_json(filename)                         #\tWrite to a file in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a63e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a6763",
   "metadata": {},
   "source": [
    "# create DF from a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36480f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col1 first': [1,2,3,32,12,6 ,45], 'col2': [4,5,6,43, 7,78,9], 'col3': [7,8,8,8,32,87,8]}\n",
    "df = pd.DataFrame.from_dict(data) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e95e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series([2,3,5,7,9])\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1364f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aadbbe4",
   "metadata": {},
   "source": [
    "#  summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac45846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.col3.value_counts()\n",
    "df.col3.unique()\n",
    "df.col3.mean()\n",
    "df['col3'].dtypes\n",
    "df['col3'].astype(str)  # Change the type of values of a column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23888d3",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['col1 first'])    # If there is a space, ' ' in the name\n",
    "print(df.col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9135a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['col2', 'col3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883bef6",
   "metadata": {},
   "source": [
    "# unique values of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d1c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.col3.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f9d19",
   "metadata": {},
   "source": [
    "# Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d678ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab rows that have a specific value for col3\n",
    "df[df['col3']==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3df56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tow conditions\n",
    "df[(df['col3']==8) & (df['col2']!=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows1,2,4,6\n",
    "indices = [1,2,4,6]\n",
    "df.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c13961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows 4,5,0 and Col 2,3\n",
    "df\n",
    "indices = [4,5,0]\n",
    "cols = ['col3','col2']\n",
    "df[cols].loc[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb25b5",
   "metadata": {},
   "source": [
    "# Indexing with iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to a row\n",
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c07afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poin to a cell of dataframe\n",
    "df.iloc[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0d2aa",
   "metadata": {},
   "source": [
    "# Indexing with loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ee44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = df.copy()\n",
    "state.set_index('col1 first', inplace=True)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ea3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.loc[32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf60b7c",
   "metadata": {},
   "source": [
    "# Dropping Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20151ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a30b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaeb108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropp All the rows that have null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99314003",
   "metadata": {},
   "source": [
    "# Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09abeba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('col1 first', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1555a7ca",
   "metadata": {},
   "source": [
    "# Creating calculated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col4'] = df['col2']+df['col3']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874db82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm an economical wine buyer. Which wine is the \"best bargain\"? Create a variable bargain_wine with the title of the wine with the highest points-to-price ratio in the dataset\n",
    "# bargain_idx = (reviews.points / reviews.price).idxmax()\n",
    "# bargain_wine =  reviews.loc[bargain_idx, 'title']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c68235",
   "metadata": {},
   "source": [
    "# Updating all column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col4'] = [(str(data) + 'total') for data in df['col4']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260c0b5",
   "metadata": {},
   "source": [
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4502ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.col4.map(lambda p: p + 'Yes')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(row):\n",
    "    row.col2 = row.col2 - 2\n",
    "    return row\n",
    "\n",
    "df.apply(function, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ae01f",
   "metadata": {},
   "source": [
    "# Updating a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2186b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,-1] = 'TOTAL'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b61eb0",
   "metadata": {},
   "source": [
    "# Condition based updating using Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852aab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col4'] = df['col4'].apply(lambda x: 1 if x=='14total' else 0) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc6791",
   "metadata": {},
   "source": [
    "# Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44656462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv')\n",
    "df.to_json()\n",
    "df.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883312d",
   "metadata": {},
   "source": [
    "# Delete a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176e8e6",
   "metadata": {},
   "source": [
    "# Group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col1 first': [1,3,3,32,12,6 ,45], 'col2': [4,5,6,43, 7,78,9], 'col3': [7,8,8,8,32,87,8]}\n",
    "df = pd.DataFrame.from_dict(data) \n",
    "print(df.groupby('col3').col3.count())\n",
    "print(df.groupby('col3')['col1 first'].min())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ed8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives us the first amount of col1 by each group - Avalin tekrare har group\n",
    "df.groupby('col3').apply(lambda df2: df2['col1 first'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['col3', 'col1 first']).apply(lambda x:  x.loc[x.col2.idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101097d",
   "metadata": {},
   "source": [
    "# agg()\n",
    "    lets you run a bunch of different functions on your DataFrame simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a30233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['col3']).col2.agg([len, min, max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac1eca",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='col2')\n",
    "# df.sort_values(by='col2',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdaf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  you can sort by more than one column at a time\n",
    "df.sort_values(by=['col1 first', 'col2'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb155ffb",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col1 first': [1,3,3,32,12,6 ,45], 'col2': [4,5,6,43, 7,78,9], 'col3': [7,8,8,8,32,87,8]}\n",
    "df = pd.DataFrame.from_dict(data) \n",
    "df[pd.isnull(df.col2)]\n",
    "df.col2.fillna(\"Unknown\", inplace=True)\n",
    "df.col3.replace(8, \"/oo\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57da499",
   "metadata": {},
   "source": [
    "# Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c341148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'col1 first': 'col1'})  # Rename a column\n",
    "df.rename(index={0: 'firstEntry', 1: 'secondEntry'})\n",
    "df.rename_axis('wines', axis='rows') # Rename the index name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a72fc5",
   "metadata": {},
   "source": [
    "# Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.DataFrame({\"col11\":[1,2,3], 'col12':[4,5,6]})\n",
    "second = pd.DataFrame({\"col11\":[1,2,3], 'col22':[4,5,6]})\n",
    "\n",
    "pd.concat([first, second])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f3de93",
   "metadata": {},
   "source": [
    "# join() \n",
    "lets you combine different DataFrame objects which have an index in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342dbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_string()  #return the entire DataFrame\n",
    "df.drop_duplicates()    # remove duplicates from a Pandas DataFrame?\n",
    "df.duplicated()   #  discover if a row is a duplicate?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
